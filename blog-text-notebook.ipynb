{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost Perfect: A Discussion on Quasi-Experiments Techniques\n",
    "\n",
    "Quasi-experiments are experiments that leverage the principal from randomized tests, but are not equivalent\n",
    "\n",
    "Any technique that can be used to estimate causal effects from observational data can be used to extract the causal effect from an quasi-experiment. The use of these causal inferences techniques in quasi-experiments is the reduction in the variance and bias of the calculated ATT (or ATE), similarly to the effect these techniques in randomized experiments. \n",
    "\n",
    "However, one of the biggest problems with using causal inference techniques is that they inevitably rely on assumptions about the causal links between variables. While there are advancements in causal discovery, in practice one never consider all possible configurations between cofounding, treatment, and target variables. Instead, we basically always create a Directed Acyclic Graph (DAG) to lay out the causal relationships in such way that the scientists behind, their piers, and clients are satisfied with.\n",
    "\n",
    "\n",
    "\n",
    "\"CUPED is just linear regression using a pre-experimental covariate.\"[2]\n",
    "\n",
    "Following, we give a quick overview of the methods we cover in this benchmark, for a better in-depth understading of each method, we provide multiple contents where you can learn more about them\n",
    "\n",
    "TL:DR:\n",
    "- the best technique is XXXXXXX\n",
    "- but it is still worse than when using an ensemble of (XXXXXXXXX) by XXXXXXX\n",
    "- backtest with historical data to assess accuracy of ATT estimating model\n",
    "- you can use previous randomized tests to calibrate hyperparameters (and possible even the parameters themselves) of your models\n",
    "\n",
    "# Techniques Overview\n",
    "\n",
    "## Matching + Differences-in-Differences (CausalPy)\n",
    "\n",
    "### Propensity Score\n",
    "\n",
    "### Mahalanobis Distance\n",
    "\n",
    "## (Augmented) Synthetic Control (CausalPy & GeoLift)\n",
    "\n",
    "## Meta-Learners (CausalML)\n",
    "    \n",
    "## Double ML (EconML)\n",
    "\n",
    "## Uplift-Trees (CausalML)\n",
    "\n",
    "## Do Method (DoWhy)\n",
    "\n",
    "# Comparisons\n",
    "## Methodology\n",
    "\n",
    "## Datasets\n",
    "- [Iowa Licor Sales](https://www.kaggle.com/datasets/residentmario/iowa-liquor-sales)\n",
    "- [Wallmart Dataset](https://www.kaggle.com/datasets/yasserh/walmart-dataset)\n",
    "- [Supermarket Sales](https://www.kaggle.com/datasets/aungpyaeap/supermarket-sales)\n",
    "- [Superstore Sales Dataset](https://www.kaggle.com/datasets/rohitsahoo/sales-forecasting)\n",
    "- [Lifetime Value](https://www.kaggle.com/datasets/baetulo/lifetime-value)\n",
    "\n",
    "## Example: Iowa Licor Sales\n",
    "\n",
    "\n",
    "# Hacks: Improving your models\n",
    "\n",
    "## Backtest using historic data\n",
    "\n",
    "## Calibrate using previous randomized tests\n",
    "\n",
    "## Don't limit yourself with just one model\n",
    "Similar to how in typical machine-learning contests the winning contestant usually consists of an ensemble model of distinct methodologies (e.g. neural-networks and tree-based models), we also reduce performance of ATT when using multiple models. Below is a comparison between using either XXXXXXX or XXXXX to using both.\n",
    "\n",
    "# References\n",
    "1) [Causal Inference, The Mixtape](https://mixtape.scunning.com)\n",
    "2) [Causality, Judea Pearl](https://www.amazon.co.uk/Causality-Judea-Pearl/dp/052189560X/ref=sr_1_1?crid=1KVB0KSO1OWMO&keywords=causality+judea&qid=1705423557&sprefix=causality+judea%2Caps%2C78&sr=8-1)\n",
    "3) [Causal Inference in Statistics, Judea Pearl, Madelyn Glymour, Nicholas P. Jewell](https://www.amazon.co.uk/Causal-Inference-Statistics-Judea-Pearl/dp/1119186846/ref=sr_1_1?crid=1SP7ANTNKW60K&keywords=causal+inference+in+statistics&qid=1705423576&sprefix=causal+inference+in+%2Caps%2C81&sr=8-1)\n",
    "4) [Variance reduction in experiments using covariate adjustment techniques](https://medium.com/glovo-engineering/variance-reduction-in-experiments-using-covariate-adjustment-techniques-717b1e450185)\n",
    "5) [How Booking.com increases the power of online experiments with CUPED](https://booking.ai/how-booking-com-increases-the-power-of-online-experiments-with-cuped-995d186fff1d)\n",
    "6) [CausalML](https://causalml.readthedocs.io/en/latest/index.html)\n",
    "7) [EconML](https://econml.azurewebsites.net/index.html)\n",
    "8) [CausalPy](https://causalpy.readthedocs.io/en/latest/)\n",
    "9) [DoWhy](https://www.pywhy.org/dowhy/v0.11.1/#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (967379724.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Quasi-experiments are experiments that leverage the principal from randomized tests, but are not equivalent\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_methods_venv",
   "language": "python",
   "name": "causal_methods_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
